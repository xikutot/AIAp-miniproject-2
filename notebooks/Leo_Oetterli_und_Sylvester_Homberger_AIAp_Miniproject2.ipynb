{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# AIAp Miniproject 2\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Imports](#imports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from keras import utils as keras_utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### b) Citation and description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Citation: \n",
    "> Llamas, J. (2017). Architectural Heritage Elements Dataset: 64 (creative commons) revised (Version 1) [Dataset; .Jpg in .Zip]. Fundación CARTIF. https://correo.cartif.es/home/joslla@cartif.es/Briefcase/Architectural_Heritage_Elements_image_Dataset/Architectural_Heritage_Elements_Dataset_128%28creative_commons%29.zip\n",
    "\n",
    "- **Title:** Architectural Heritage Elements Dataset\n",
    "- **Subtitle:** 128 (creative commons) revised\n",
    "- **Version:** 1\n",
    "- **Publication Date:** 2017-02-20\n",
    "- **Author:** Jose Llamas\n",
    "- **Organization:** Fundación CARTIF\n",
    "- **Source:** https://correo.cartif.es/home/joslla@cartif.es/Briefcase/Architectural_Heritage_Elements_image_Dataset/Architectural_Heritage_Elements_Dataset_128%28creative_commons%29.zip\n",
    "- **Media:** .jpg in .zip\n",
    "- **Download:** 2024-03-26\n",
    "\n",
    "The raw data was extracted with Windows. We then added it to our repository on the Gitlab instance of OST.\n",
    "\n",
    "This dataset consists of 10437 RGB 64x64 jpg images classified in 11 categories:\n",
    "- Altar: 828 images\n",
    "- Apse: 505 images\n",
    "- Bell tower: 1057 images\n",
    "- Column: 1914 images\n",
    "- Dome (inner): 589 images\n",
    "- Dome (outer): 1175 images\n",
    "- Flying buttress: 405 images\n",
    "- Gargoyle (and Chimera): 1562 images\n",
    "- Portal: 307 images\n",
    "- Stained glass: 998 images\n",
    "- Vault: 1097 images\n",
    "\n",
    "As \"flying buttress\" and \"portal\" do not satisfy the minimal samples requirement of 500, we dropped them. Our adjusted dataset therefore fulfils the requirements:\n",
    "- RGB images of 9 classes\n",
    "- Each has more than 500 samples and the total is 9725 images\n",
    "- They have a resolution of 64x64 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9725 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(os.getcwd()).parent / \"data\"\n",
    "raw_folder = data_folder / \"raw\" / \"Architectural_Heritage_Elements_Dataset_64(creative_commons)_revised\"\n",
    "\n",
    "dataset = keras_utils.image_dataset_from_directory(raw_folder, image_size=(64, 64), batch_size=None, seed=SEED)\n",
    "\n",
    "label_to_class = dataset.class_names\n",
    "class_to_label = dict(zip(label_to_class, range(len(label_to_class))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### c) Splitting into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_val_data, test_data = keras_utils.split_dataset(dataset, left_size=0.7, seed=64)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Architecture 1 (underfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Architecture 2 (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Architecture 2 (optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Quantification of the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiap-miniproject-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
